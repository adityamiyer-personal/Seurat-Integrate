% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/trVAE.R
\name{trVAEIntegration}
\alias{trVAEIntegration}
\title{Run trVAE on Seurat's \link[SeuratObject]{Assay5} object through \code{\link[Seurat]{IntegrateLayers}}}
\usage{
trVAEIntegration(
  object,
  orig = NULL,
  groups = NULL,
  groups.name = NULL,
  surgery.name = NULL,
  surgery.sort = TRUE,
  features = NULL,
  layers = ifelse(recon.loss == "mse", "data", "counts"),
  scale.layer = "scale.data",
  conda_env = NULL,
  new.reduction = "integrated.trVAE",
  reduction.key = "trVAElatent_",
  torch.intraop.threads = 4L,
  torch.interop.threads = NULL,
  model.save.dir = NULL,
  ndims.out = 10L,
  recon.loss = c("nb", "zinb", "mse"),
  hidden_layer_sizes = c(256L, 64L),
  dr_rate = 0.05,
  use_mmd = TRUE,
  mmd_on = c("z", "y"),
  mmd_boundary = NULL,
  beta = 1,
  use_bn = FALSE,
  use_ln = TRUE,
  n_epochs = 400L,
  lr = 0.001,
  eps = 0.01,
  hide.py.warn = T,
  seed.use = 42L,
  verbose = TRUE,
  ...
)
}
\arguments{
\item{object}{A \code{\link[SeuratObject]{Seurat}} object
(or an \code{\link[SeuratObject]{Assay5}} object if
not called by \code{\link[Seurat]{IntegrateLayers}})}

\item{orig}{\code{\link[SeuratObject]{DimReduc}} object. Not to be set
directly when called with \code{\link[Seurat]{IntegrateLayers}}, use
\code{orig.reduction} argument instead}

\item{groups}{A \bold{named} data frame with grouping information. Can also
contain surgery groups to perform surgery integration.}

\item{groups.name}{Column name from \code{groups} data frame that stores
grouping information. If \code{groups.name = NULL}, the first column is used}

\item{surgery.name}{Column name from \code{groups} data frame that stores
surgery information. If \code{surgery.name = NULL}, a one shot integration is
performed}

\item{features}{Vector of feature names to input to the integration method.
When \code{features = NULL} (default), the
\code{\link[SeuratObject]{VariableFeatures}} are used. To pass all features,
use the output of \code{\link[SeuratObject]{Features}()}}

\item{layers}{Name of the layers to use in the integration}

\item{conda_env}{Path to conda environment to run trVAE (should also
contain the scipy python module).  By default, uses the conda environment
registered for trVAE in the conda environment manager}

\item{new.reduction}{Name of the new integrated dimensional reduction}

\item{reduction.key}{Key for the new integrated dimensional reduction}

\item{torch.intraop.threads}{Number of intra-op threads available to torch
when training on CPU instead of GPU. Set via \code{torch.set_num_threads()}.}

\item{torch.interop.threads}{Number of intra-op threads available to torch
when training on CPU instead of GPU. Set via \code{torch.set_num_interop_threads()}.
Can only be changed once, on first call.}

\item{model.save.dir}{Path to a directory to save the model(s) to. Uses
\code{TRVAE.save()}. Does not save anndata. \code{model.save.dir = NULL}
(default) disables saving the model(s).}

\item{ndims.out}{Number of dimensions for \code{new.reduction} output.
Corresponds to \code{latent_dim} argument in the original API of TRVAE from
\pkg{scArches}}

\item{recon.loss}{Definition of Reconstruction-Loss-Method. One of 'mse', 'nb'
or 'zinb' (hence mean squared error, negative binomial and zero-inflated
negative binomial respectively). Recommended to set \code{layer = "data"} for
'mse' (and \code{layer = "counts"} for (zi)nb)}

\item{hidden_layer_sizes}{Hidden layer sizes for encoder network}

\item{dr_rate}{Dropout rate applied to all layers. \code{dr_rate = 0} disables
dropout.}

\item{use_mmd}{Whether an additional MMD loss is to be calculated on the
latent dim. (see next argument)}

\item{mmd_on}{Choose on which layer MMD loss will be calculated on. One of 'z'
for latent dim or 'y' for the first decoder layer. Only applies when
\code{use_mmd = TRUE}}

\item{mmd_boundary}{On how many groups the MMD loss should be calculated on.
If \code{mmd_boundary = NULL} (default), MMD is calculated on all groups.
Only applies when \code{use_mmd = TRUE}}

\item{beta}{Scaling factor for MMD loss (1 by default). Only applies when
\code{use_mmd = TRUE}}

\item{use_bn}{Whether to apply a batch normalization to layers}

\item{use_ln}{Whether to apply a layer normalization to layers}

\item{n_epochs}{Maximum number of epochs to train the model}

\item{lr}{Learning rate for training}

\item{eps}{\code{torch.optim.Adam} eps parameter to improve numerical stability
(see \href{https://pytorch.org/docs/stable/generated/torch.optim.Adam.html}{here})}

\item{hide.py.warn}{Disables some uninformative warnings from torch}

\item{seed.use}{An integer to generate reproducible outputs.
Set \code{seed.use = NULL} to disable}

\item{verbose}{Print messages. Set to \code{FALSE} to disable}

\item{...}{Additional arguments to be passed to
\code{scarches.models.TRVAE.train}, \code{TRVAE.load_query_data}
or \code{TRVAE.get_latent} (see \strong{Details} section)}
}
\value{
A list containing:
\itemize{
  \item \strong{Without surgery groups:} a new DimReduc of name
  \code{new.reduction} (key set to \code{reduction.key}) consisting of the
  latent space of the model with \code{ndims.out} dimensions.
  \item \strong{With surgery groups:} one new DimReduc per surgery groups of
  name \code{new.reduction_[surgery.group]} (key set to
  \code{reduction.key[surgery.group]}) consisting of the latent space of the
  corresponding models with \code{ndims.out} dimensions,  as well as a 'full'
  latent representation of name \code{new.reduction_[surgery1]_[surgery2]_...}
  and key set to \code{reduction.keyFull-}.
}
When called via \code{\link[Seurat]{IntegrateLayers}}, a Seurat object with
the new reduction and/or assay is returned
}
\description{
A wrapper to run \code{trVAE} on multi-layered Seurat V5 object.
Requires a conda environment with \pkg{scArches} and necessary dependencies


\strong{Recommendations}: use raw counts (except for \code{recon.loss = "mse"})
and all features (\code{features = Features(object), layers = "counts",
scale.layer = NULL}).
}
\details{
This wrappers calls three to four python functions through \pkg{reticulate}.
Find the \pkg{trVAE}-specific arguments there:
\itemize{
  \item{model initiation:} {
  \href{https://docs.scarches.org/en/latest/api/models.html#scarches.models.TRVAE}{scarches.models.TRVAE}}
  \item{training:} {
  \href{https://docs.scarches.org/en/latest/api/models.html#scarches.models.TRVAE.train}{TRVAE.train}, which relies on
  \href{https://github.com/theislab/scarches/blob/51a0294ca987dabffb6d109178e0f69a90f9c24f/scarches/trainers/trvae/trainer.py#L14}{scarches.trainers.trvae.train.Trainer}}
  \item{post-training:} {
  \href{https://github.com/theislab/scarches/blob/51a0294ca987dabffb6d109178e0f69a90f9c24f/scarches/models/base/_base.py#L285}{scarches.models.base._base.CVAELatentsMixin.get_latent}}
  \item{surgery initiation:} {
  \href{https://github.com/theislab/scarches/blob/51a0294ca987dabffb6d109178e0f69a90f9c24f/scarches/models/base/_base.py#L200}{scarches.models.base._base.SurgeryMixin.load_query_data}}
}

Note that \code{seed.use} is passed to \code{torch.manual_seed()}.
If it is not sufficient to achieve full reproducibility, set
\code{mean = TRUE} or \code{mean_var = TRUE}
}
\note{
This function requires the
\href{https://docs.scarches.org/}{\pkg{scArches}} package
to be installed (along with \pkg{scipy})
}
\examples{
\dontrun{
# Preprocessing
obj <- SeuratData::LoadData("pbmcsca")
obj[["RNA"]] <- split(obj[["RNA"]], f = obj$Method)
obj <- NormalizeData(obj)
obj <- FindVariableFeatures(obj)
obj <- ScaleData(obj)
obj <- RunPCA(obj)

# After preprocessing, we integrate layers:
obj <- IntegrateLayers(object = obj, method = trVAEIntegration,
                       features = Features(obj), scale.layer = NULL,
                       layers = 'counts', groups = obj[[]],
                       groups.name = 'Method')

# To enable surgery and full reproducibility and change the recon loss method:
obj <- IntegrateLayers(object = obj, method = trVAEIntegration,
                       features = Features(obj), scale.layer = NULL,
                       layers = 'data', groups = obj[[]],
                       groups.name = 'Method', surgery.name = 'Experiment',
                       mean_var = TRUE, recon.loss = 'mse')
}

}
\references{
Lotfollahi, M., Naghipourfar, M., Theis, F. J. & Wolf, F. A.
Conditional out-of-distribution generation for unpaired data using transfer
VAE. Bioinformatics 36, i610–i617 (2020).
\href{https://doi.org/10.1093/bioinformatics/btaa800}{DOI}

Lotfollahi, M., Naghipourfar, M., Luecken, M. D., Khajavi, M.,
Büttner, M., Wagenstetter, M., Avsec, Ž., Gayoso, A., Yosef, N., Interlandi,
M., Rybakov, S., Misharin, A. V. & Theis, F. J. Mapping single-cell data to
reference atlases by transfer learning. Nat Biotechnol 40, 121–130 (2021).
\href{https://doi.org/10.1038/s41587-021-01001-7}{DOI}
}
\seealso{
\code{\link[Seurat]{IntegrateLayers}}, \code{\link[Seurat]{writing-integration}}
}
