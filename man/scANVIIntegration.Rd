% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/scANVI.R
\name{scANVIIntegration}
\alias{scANVIIntegration}
\title{Run scANVI on Seurat's \link[SeuratObject]{Assay5} object through \code{\link[Seurat]{IntegrateLayers}}}
\usage{
scANVIIntegration(
  object,
  groups = NULL,
  groups.name = NULL,
  labels.name = NULL,
  labels.null = NULL,
  features = NULL,
  layers = "counts",
  scale.layer = "scale.data",
  conda_env = NULL,
  new.reduction = "integrated.scANVI",
  reduction.key = "scANVIlatent_",
  torch.intraop.threads = 4L,
  torch.interop.threads = NULL,
  model.save.dir = NULL,
  ndims.out = 10,
  n_hidden = 128L,
  n_layers = 1L,
  dropout_rate = 0.1,
  dispersion = c("gene", "gene-batch", "gene-label", "gene-cell"),
  gene_likelihood = c("zinb", "nb", "poisson"),
  linear_classifier = FALSE,
  max_epochs = NULL,
  train_size = 0.9,
  batch_size = 128L,
  seed.use = 42L,
  verbose = TRUE,
  verbose.scvi = c("INFO", "NOTSET", "DEBUG", "WARNING", "ERROR", "CRITICAL"),
  ...
)
}
\arguments{
\item{object}{A \code{\link[SeuratObject]{Seurat}} object
(or an \code{\link[SeuratObject]{Assay5}} object if
not called by \code{\link[Seurat]{IntegrateLayers}})}

\item{groups}{A \bold{named} data frame with grouping information. Can also
contain cell labels to guide scANVI.}

\item{groups.name}{Column name from \code{groups} data frame that stores
grouping information. If \code{groups.name = NULL}, the first column is used}

\item{labels.name}{Column name from \code{groups} data frame that stores
cell label information. If \code{labels.name = NULL}, all cells are assigned
the same label.}

\item{labels.null}{One value of \code{groups$labels.name} that indicates unlabeled
observations. \code{labels.null = NULL} means all labels are valid. Only applies
when \code{labels.name != NULL}.}

\item{features}{Vector of feature names to input to the integration method.
When \code{features = NULL} (default), the
\code{\link[SeuratObject]{VariableFeatures}} are used. To pass all features,
use the output of \code{\link[SeuratObject]{Features}()}}

\item{layers}{Name of the layers to use in the integration.
\bold{'counts'} is highly recommended}

\item{scale.layer}{Name of the scaled layer in \code{Assay}}

\item{conda_env}{Path to conda environment to run scANVI (should also
contain the scipy python module).  By default, uses the conda environment
registered for scANVI in the conda environment manager}

\item{new.reduction}{Name of the new integrated dimensional reduction}

\item{reduction.key}{Key for the new integrated dimensional reduction}

\item{torch.intraop.threads}{Number of intra-op threads available to torch
when training on CPU instead of GPU. Set via \code{torch.set_num_threads()}.}

\item{torch.interop.threads}{Number of intra-op threads available to torch
when training on CPU instead of GPU. Set via \code{torch.set_num_interop_threads()}.
Can only be changed once, on first call.}

\item{model.save.dir}{Path to a directory to save the model to. Uses
\code{SCANVI.save()}. Does not save anndata. Note that neither the trainer
optimizer state nor the trainer history are saved.
\code{model.save.dir = NULL} (default) disables saving the model.}

\item{ndims.out}{Number of dimensions for \code{new.reduction} output.
Corresponds to \code{n_latent} argument in the original API of SCANVI}

\item{n_hidden}{Number of nodes per hidden layer.}

\item{n_layers}{Number of hidden layers used for encoder and decoder NNs.}

\item{dropout_rate}{Dropout rate for neural networks.}

\item{dispersion}{One of the following:
\itemize{
 \item \code{gene}: dispersion parameter of NB is constant per gene across cells (default)
 \item \code{gene-batch}: dispersion can differ between different batches
 \item \code{gene-label}: dispersion can differ between different labels
 \item \code{gene-cell}: dispersion can differ for every gene in every cell
}}

\item{gene_likelihood}{One of the following:
\itemize{
 \item \code{zinb}: Zero-inflated negative binomial distribution (default)
 \item \code{nb}: Negative binomial distribution
 \item \code{poisson}: Poisson distribution
}}

\item{linear_classifier}{When switched to \code{TRUE}, uses a single linear layer for
classification instead of a multi-layer perceptron.}

\item{max_epochs}{Number of passes through the dataset for semisupervised training.}

\item{train_size}{Size of training set in the range \code{[0.0, 1.0]}}

\item{batch_size}{Minibatch size to use during training.}

\item{seed.use}{An integer to generate reproducible outputs.
Set \code{seed.use = NULL} to disable}

\item{verbose}{Print messages. Set to \code{FALSE} to disable}

\item{verbose.scvi}{Verbosity level of scANVI. From quietest to talkiest:
CRITICAL, ERROR, WARNING, INFO (default), DEBUG, NOTSET}

\item{...}{Additional arguments to be passed to \code{scvi.model.SCANVI},
\code{SCANVI.setup_anndata} or \code{SCANVI.train} (see \strong{Details} section)}
}
\value{
A list containing:
\itemize{
  \item a new DimReduc of name \code{new.reduction} (key set to
  \code{reduction.key}) consisting of the latent space of the model with
  \code{ndims.out} dimensions.
}
When called via \code{\link[Seurat]{IntegrateLayers}}, a Seurat object with
the new reduction and/or assay is returned
}
\description{
A wrapper to run \code{scANVI} on multi-layered Seurat V5 object.
Requires a conda environment with \code{scvi-tools} and necessary dependencies

\strong{Recommendations}: use raw counts and all features
(\code{features = Features(object), layers = "counts"})
}
\details{
This wrappers calls three python functions through \pkg{reticulate}.
Find the \pkg{scVANVI}-specific arguments there:
\itemize{
  \item model initiation:
  \href{https://docs.scvi-tools.org/en/stable/api/reference/scvi.model.SCANVI.html#scvi-model-scanvi}{scvi.model.SCANVI}, which relies on
  \href{https://docs.scvi-tools.org/en/stable/api/reference/scvi.module.SCANVAE.html#scvi-module-scanvae}{scvi.module.SCANVAE} which in turn relies on
  \href{https://docs.scvi-tools.org/en/stable/api/reference/scvi.module.VAE.html#scvi-module-vae}{scvi.module.VAE}
  \item anndata setup:
  \href{https://docs.scvi-tools.org/en/stable/api/reference/scvi.model.SCANVI.html#scvi.model.SCANVI.setup_anndata}{SCANVI.setup_anndata}
  \item training:
  \href{https://docs.scvi-tools.org/en/stable/api/reference/scvi.model.SCANVI.html#scvi.model.SCANVI.train}{SCANVI.train}
}
}
\note{
This function requires the
\href{https://scvi-tools.org/}{\pkg{scvi-tools}} package
to be installed (along with \pkg{scipy})
}
\examples{
\dontrun{
# Preprocessing
obj <- SeuratData::LoadData("pbmcsca")
obj[["RNA"]] <- split(obj[["RNA"]], f = obj$Method)
obj <- NormalizeData(obj)
obj <- FindVariableFeatures(obj)
obj <- ScaleData(obj)
obj <- RunPCA(obj)

# After preprocessing, we integrate layers:
obj <- IntegrateLayers(object = obj, method = scANVIIntegration,
                       features = Features(obj), conda_env = 'scvi-tools',
                       layers = 'counts', groups = obj[[]], groups.name = 'Method',
                       labels.name = 'CellType', labels.null = 'Unassigned')

# To enable saving the model, add other 'nuisance' factors and increase number of threads used:
obj <- IntegrateLayers(object = obj, method = scANVIIntegration,
                       features = Features(obj), conda_env = 'scvi-tools',
                       layers = 'counts', groups = obj[[]], groups.name = "Method",
                       labels.name = "CellType", labels.null = "Unassigned",
                       categorical_covariate_keys = "Experiment",
                       continuous_covariate_keys = "percent.mito",
                       ncores = 8, model.save.dir = '~/Documents/scANVI.model')
}

}
\references{
Kingma, D. P., Rezende, D. J., Mohamed, S. & Welling, M. Semi-
Supervised Learning with Deep Generative Models. Preprint at arXiv (2014).
\href{https://doi.org/10.48550/arXiv.1406.5298}{DOI}

Xu, C., Lopez, R., Mehlman, E., Regier, J., Jordan, M. I. & Yosef, N.
Probabilistic harmonization and annotation of single‐cell transcriptomics data
with deep generative models. Molecular Systems Biology 17, (2021).
\href{https://doi.org/10.15252/msb.20209620}{DOI}
}
\seealso{
\code{\link[Seurat]{IntegrateLayers}}, \code{\link[Seurat]{writing-integration}}
}
